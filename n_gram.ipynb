{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAy2jL9qC6Db",
        "outputId": "4079c8ee-30cc-436d-c3ee-79bde4e69376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
            "To: /content/train.txt\n",
            "100% 9.87M/9.87M [00:00<00:00, 66.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy\n",
            "To: /content/test.txt\n",
            "100% 5.80k/5.80k [00:00<00:00, 8.34MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
        "!gdown --id 1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "D6g75Qvb1M10"
      },
      "outputs": [],
      "source": [
        "def st_replace(str, a , b):\n",
        "  str = str.replace(a, b)\n",
        "  return str\n",
        "def read_file(path_to_file):\n",
        "  \n",
        "  data = []\n",
        "  with open(path_to_file, 'r') as ptr:\n",
        "    for line in ptr:\n",
        "      tmp = line.strip()\n",
        "      r = ['؟', '،','!','.']\n",
        "      for letter in r:\n",
        "        tmp = st_replace(tmp, letter , ' ')\n",
        "      if not (len(tmp)<3):\n",
        "        data.append(tmp)\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "osI4vxot1XOy"
      },
      "outputs": [],
      "source": [
        "sentences = read_file('/content/train.txt')\n",
        "tests = read_file('/content/test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BBz40p67E1bl"
      },
      "outputs": [],
      "source": [
        "#calculate unigram\n",
        "\n",
        "def calc_unigram_pros(corpus):\n",
        "\n",
        "  word_count = {}\n",
        "  total_words = 0\n",
        "\n",
        "  for doc in corpus:\n",
        "    tmp = doc.split(' ')\n",
        "    \n",
        "    total_words += len(tmp)\n",
        "\n",
        "    for word in tmp:\n",
        "      if (not (word in word_count)):\n",
        "        word_count[word] = 0\n",
        "      word_count[word] = word_count[word] + 1\n",
        "\n",
        "  return word_count , total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ixSGrIv2E_He"
      },
      "outputs": [],
      "source": [
        "word_count, total_words = calc_unigram_pros(sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "EJStVQOOOR6J"
      },
      "outputs": [],
      "source": [
        "# calculate bigrams\n",
        "\n",
        "def calculate_bigram(corpus):\n",
        "  word_count = {}\n",
        "  word_dict = {}\n",
        "  total = 0\n",
        "\n",
        "  for doc in corpus:\n",
        "    tmp = doc.split(' ')\n",
        "    \n",
        "    for i in range(1, len(tmp)):\n",
        "        if not ((tmp[i-1], tmp[i]) in word_count):\n",
        "                word_count[(tmp[i-1],tmp[i])] = 0\n",
        "\n",
        "        if not tmp[i-1] in word_dict:\n",
        "          word_dict[tmp[i-1]]=[]\n",
        "\n",
        "        word_count[(tmp[i-1],tmp[i])] += 1\n",
        "        total += 1\n",
        "        if not tmp[i] in word_dict[tmp[i-1]]:\n",
        "          word_dict[tmp[i-1]].append(tmp[i])\n",
        "  \n",
        "  return word_count, word_dict, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "zRcrd8iLOkPA"
      },
      "outputs": [],
      "source": [
        "bigram_count , bigram_dict, bigram_total = calculate_bigram(sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "2R_X0c7X2ROO"
      },
      "outputs": [],
      "source": [
        "#calculate n_gram for a file\n",
        "\n",
        "def compute_freq (file:str, n:int):\n",
        "  #k = 0\n",
        "  if n >5:\n",
        "    return \n",
        "\n",
        "  sentences = read_file(file)\n",
        "  num_gram = 0\n",
        "\n",
        "  gram_dict = {}\n",
        "\n",
        "  for line in sentences:\n",
        "    #if k>7:\n",
        "    # return gram_dict\n",
        "    #k += 1\n",
        "\n",
        "    tmp = line.split(' ')\n",
        "\n",
        "    for j in range(n, len(tmp)+1):\n",
        "      num_gram += 1\n",
        "      if not (tuple(tmp[j-n:j])in gram_dict):\n",
        "        gram_dict[tuple(tmp[j-n:j])] = 0\n",
        "      gram_dict[tuple(tmp[j-n:j])] += 1\n",
        "    \n",
        "  \n",
        "  return gram_dict, num_gram\n",
        "        \n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGyhHRGJ4859"
      },
      "source": [
        "Q 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "esD3-WqQGvkL"
      },
      "outputs": [],
      "source": [
        "def dritchlet_prob(word_1, word_2):\n",
        "  p_bg = 1 / total_words\n",
        "  miu = 0.01\n",
        "\n",
        "  if not (word_1, word_2) in bigram_count:\n",
        "    a = 0\n",
        "  else: \n",
        "    a = bigram_count[(word_1, word_2)]\n",
        "  \n",
        "  b = word_count[word_1]\n",
        "  \n",
        "\n",
        "  return (a + miu*p_bg)/ (b + miu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1UyefVS3CubB"
      },
      "outputs": [],
      "source": [
        "#COMPLETE SENTENCE WITH DRITCHLET\n",
        "\n",
        "def complete_dritchlet(saint, to_fill):\n",
        "  #just for one or two words\n",
        "\n",
        "  s = saint\n",
        "  saint = saint.split(' ')\n",
        "\n",
        "  last = saint[-1]\n",
        "  \n",
        "  \n",
        "  \n",
        "  if to_fill == 1:\n",
        "    max = 0\n",
        "    fill = ''\n",
        "\n",
        "    for i in bigram_dict[last]:\n",
        "        if bigram_count[(last,i)]>max:\n",
        "          max = bigram_count[(last,i)]\n",
        "          fill = i\n",
        "    print(s+ ' '+fill)\n",
        "    return fill\n",
        "\n",
        "  co = 5\n",
        "  maxp = 0\n",
        "  first = ''\n",
        "  second = ''\n",
        "\n",
        "  for i in bigram_dict[last]:\n",
        "    if i in bigram_dict:\n",
        "     for j in bigram_dict[i]:\n",
        "       d_1 = dritchlet_prob(last,i)\n",
        "       d_2 = dritchlet_prob(i, j)\n",
        "       p = d_1 * d_2\n",
        "       if p > maxp:\n",
        "         maxp = p\n",
        "         first, second = i , j\n",
        "\n",
        "  print(s + ' '+first+' '+second)\n",
        "  return first , second\n",
        "  '''\n",
        "    print(i, bigram_count[(last,i)])\n",
        "    if co == 0:\n",
        "      break\n",
        "    co-= 1\n",
        "  '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNRtJKT7Jtn_",
        "outputId": "795e0d14-b3de-4304-ae7e-5ffd2297a8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چون مشک سیه بود مرا هر دو زلف تو\n",
            "\n",
            "\n",
            "گر خورد سوگند هم آن را\n",
            "\n",
            "\n",
            "زانک نفس آشفته تر گردد از آن\n",
            "\n",
            "\n",
            "ازی ن زشت تر در جهان رنگ و\n",
            "\n",
            "\n",
            "دوست در خانه و ما گرد کوی تو\n",
            "\n",
            "\n",
            "شب است و شمع و شراب و از\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "s_1 = 'چون مشک سیه بود مرا هر دو'\n",
        "s_2 = 'گر خورد سوگند هم آن'\n",
        "s_3 = 'زانک نفس آشفته تر گردد از'\n",
        "s_4 = 'ازی ن زشت تر در جهان رنگ'\n",
        "s_5 = 'دوست در خانه و ما گرد'\n",
        "s_6 = 'شب است و شمع و شراب و'\n",
        "L = [(s_1, 2), (s_2, 1),(s_3, 1),(s_4, 1),(s_5, 2),(s_6, 1)]\n",
        "\n",
        "for i in L:\n",
        "  complete_dritchlet(i[0], i[1])\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXJ28s1Y5JKK"
      },
      "source": [
        "Q 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "W3Bx33bxOcHG"
      },
      "outputs": [],
      "source": [
        "word_count_test, total_words_test= calc_unigram_pros(tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "yTa4GXv1OJkm"
      },
      "outputs": [],
      "source": [
        "bigram_count_test , bigram_dict_test ,bigram_total_test= calculate_bigram(tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ZDipHgA3OGLF"
      },
      "outputs": [],
      "source": [
        "def dritchlet_prob_test (word_1, word_2):\n",
        "  p_bg = 1 / total_words_test\n",
        "  miu = 0.01\n",
        "\n",
        "  if not (word_1, word_2) in bigram_count_test:\n",
        "    a = 0\n",
        "  else: \n",
        "    a = bigram_count_test[(word_1, word_2)]\n",
        "  \n",
        "  b = word_count_test[word_1]\n",
        "  \n",
        "\n",
        "  return ((a + miu*p_bg)/ (b + miu)) * (b/ total_words_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGVQQ0Fd5KWm",
        "outputId": "8b86682c-5bd2-400b-ec37-c0868addd77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309.22578121610934\n"
          ]
        }
      ],
      "source": [
        "#perplexity of test\n",
        "\n",
        "import math\n",
        "\n",
        "H = 0\n",
        "\n",
        "for i in word_count_test:\n",
        "  for j in word_count_test:\n",
        "      p = dritchlet_prob_test(i, j)\n",
        "      H += -(p * math.log2(p))\n",
        "\n",
        "print(2 ** H )\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_3Sm0sCXnW8"
      },
      "source": [
        "Q 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZTV7CXMnaVJ",
        "outputId": "82bb2d02-c597-462a-bab7-be570b583873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945686\n"
          ]
        }
      ],
      "source": [
        "#tokenizing 3 _grams \n",
        "\n",
        "\n",
        "sequences = list()\n",
        "for  line in sentences:\n",
        "  tmp = line.split(' ')\n",
        "\n",
        "  c -= 1\n",
        "  if c == 0:\n",
        "    break\n",
        "\n",
        "  for i in range(3, len(tmp)+1):\n",
        "    seq = tmp[i-3:i]\n",
        "    liz = ' '.join(seq)\n",
        "    sequences.append(liz)\n",
        "\n",
        "print(len(sequences))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "V3bXdLmdrLf7"
      },
      "outputs": [],
      "source": [
        "#maping words to int\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sequences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDZjLyDKrz7k",
        "outputId": "dfb40975-0fac-425b-d862-3803e1cc075f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30, 247, 17]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "sequences[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "9P5cGP4ysBZq"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu_fPC8csK6n",
        "outputId": "102636f6-a1d0-40da-9c61-9a19a36ccac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56699"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "fSzILbcJsQNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f44e6b-4d5f-41f9-9a13-f1e7ac6a5005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "sequences = np.array(sequences)\n",
        "\n",
        "#split sequences into input x and output y\n",
        "x, y = sequences[:-1], sequences[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "xhfX-qSIurS7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes = vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ieorGakmvEsi"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Qyi3Kq2yuh",
        "outputId": "3a471353-c299-4981-a9c2-da0e0e00d645"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56699,)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train , x_test, y_train, y_test = train_test_split(x, y, test_size=0.40,random_state =42)\n",
        "length = int(len(x_test)/2)\n",
        "\n",
        "y_validation = y_test[0:length]\n",
        "x_validation = x_test[0:length]\n",
        "\n",
        "y_test = y_test[length:2+length]\n",
        "x_test = x_test[length:2+length]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "n9smCQc_3nw8",
        "outputId": "9d4f802e-98fa-441d-cfb0-996518bbe760"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-945145bbbffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [945685, 3]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}