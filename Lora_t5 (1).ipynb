{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies and constancts"
      ],
      "metadata": {
        "id": "aFenaqaERj1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets transformers\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import T5TokenizerFast, T5ForConditionalGeneration, DataCollatorForSeq2Seq"
      ],
      "metadata": {
        "id": "uqjFnYI-_kDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MODEL_NAME = 't5-small'\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 5\n",
        "RANK = 8\n",
        "ALPHA = 4.0"
      ],
      "metadata": {
        "id": "hef7kB4bOfhU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "eCKXJQi3RqQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('imdb')\n",
        "dataset.pop('unsupervised')"
      ],
      "metadata": {
        "id": "OQGsEEEIOns0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id2label(ids):\n",
        "    label_names = ['negative', 'positive']\n",
        "    return [label_names[id] for id in ids]\n",
        "\n",
        "def label2id(labels):\n",
        "    label_names_dict = {\n",
        "        'negative': 0,\n",
        "        'positive': 1\n",
        "    }\n",
        "    return [\n",
        "        label_names_dict.get(label, 2)\n",
        "        for label in labels\n",
        "    ]"
      ],
      "metadata": {
        "id": "sOcNgF4aOi_3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5TokenizerFast.from_pretrained(BASE_MODEL_NAME)"
      ],
      "metadata": {
        "id": "HCtFZ9AzOr-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace('<br />', ' ')\n",
        "    return text\n",
        "\n",
        "def map_function(row):\n",
        "    processed_input = [\n",
        "        preprocess_input(text)\n",
        "        for text in row['text']\n",
        "    ]\n",
        "    input_info = tokenizer(processed_input, truncation=True, max_length=256)\n",
        "    output_info = tokenizer(id2label(row['label']))\n",
        "    return {\n",
        "        **input_info,\n",
        "        'labels': output_info.input_ids\n",
        "    }\n",
        "\n",
        "\n",
        "dataset = dataset.map(map_function, batched=True)\n",
        "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ],
      "metadata": {
        "id": "q8RhcGnuOsx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_fn = DataCollatorForSeq2Seq(\n",
        "    tokenizer, return_tensors='pt', padding='longest',\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset['train'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=col_fn,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset['test'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=col_fn,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "kuHaPdaWQCtQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model and training loop"
      ],
      "metadata": {
        "id": "XTIrHPM7RzBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(BASE_MODEL_NAME)"
      ],
      "metadata": {
        "id": "Pvp-Z0VxOzBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "compute_metrics = accuracy_score"
      ],
      "metadata": {
        "id": "bMW45OqrO1aW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "id": "Rf7OXY1EO_Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, loader, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    batch_losses = []\n",
        "\n",
        "    for row in tqdm(loader, desc='Training:'):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(**row.to(model.device))\n",
        "        loss = out.loss\n",
        "\n",
        "        batch_loss_value = loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_losses.append(batch_loss_value)\n",
        "\n",
        "    loss_value = np.mean(batch_losses)\n",
        "    return {'train_loss': loss_value}\n",
        "\n",
        "def _predict(model, row):\n",
        "    return model.generate(\n",
        "        input_ids=row.input_ids,\n",
        "        attention_mask=row.attention_mask,\n",
        "        max_length=5\n",
        "    )\n",
        "\n",
        "def tokenizer_ids_to_label(all_input_ids):\n",
        "    return tokenizer.batch_decode(all_input_ids, skip_special_tokens=True)\n",
        "\n",
        "def valid_loop(model, loader, compute_metrics):\n",
        "    model.eval()\n",
        "\n",
        "    all_true = []\n",
        "    all_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for row in tqdm(loader, desc='Validating:'):\n",
        "            row.to(model.device)\n",
        "            pred = _predict(model, row)\n",
        "\n",
        "            all_true += row.labels.detach().cpu().tolist()\n",
        "            all_pred += pred.detach().cpu().tolist()\n",
        "\n",
        "    all_true = label2id(tokenizer_ids_to_label(all_true))\n",
        "    all_pred = label2id(tokenizer_ids_to_label(all_pred))\n",
        "\n",
        "    return {'valid_acc': compute_metrics(y_true=all_true, y_pred=all_pred)}"
      ],
      "metadata": {
        "id": "TzeEFj4rPw0M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "compute_metrics = accuracy_score"
      ],
      "metadata": {
        "id": "1HZPJPFsP0jG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Lora_loop(model):\n",
        "    all_results = []\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_results = {'epoch': epoch}\n",
        "\n",
        "        epoch_results.update(\n",
        "            train_loop(\n",
        "                model=model,\n",
        "                loader=train_loader,\n",
        "                optimizer=optimizer,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        epoch_results.update(\n",
        "            valid_loop(\n",
        "                model=model,\n",
        "                loader=test_loader,\n",
        "                compute_metrics=compute_metrics,\n",
        "            )\n",
        "        )\n",
        "        all_results.append(epoch_results)\n",
        "\n",
        "        display.clear_output()\n",
        "        display.display(pd.DataFrame(all_results).set_index('epoch'))\n",
        "\n",
        "    display.clear_output()\n",
        "\n",
        "    best_score = pd.DataFrame(all_results)['valid_acc'].max() * 100\n",
        "    print('Best model preformance is: %%%.1f' % best_score)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-OA5ehHbPEE5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using PEFT for LoRA"
      ],
      "metadata": {
        "id": "zT89QeMaR-Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "RANK = 8\n",
        "model = T5ForConditionalGeneration.from_pretrained(BASE_MODEL_NAME)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=RANK,\n",
        "    lora_alpha = ALPHA,\n",
        "    target_modules = [\"q\", \"v\"],\n",
        "    lora_dropout = 0,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxMw3sx8PtRh",
        "outputId": "b0f5531c-7065-401b-b15b-c8d78b17361e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850403779272945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lora_loop(model)"
      ],
      "metadata": {
        "id": "C1vl_c_ORCGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9f9OU58RRyL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}